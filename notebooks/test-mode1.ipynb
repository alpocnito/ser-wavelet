{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6b0040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f10998fa870>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(\n",
    "                  os.path.dirname(\"test-mode1\"), \n",
    "                  os.pardir)\n",
    ")\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from train import train, evaluate\n",
    "from src.dataset import create_dataloader\n",
    "from src.utils import feature_extraction_pipeline, read_features_files, choose_model, read_feature\n",
    "from src.models.utils import SaveBestModel, weight_init\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from typing import Dict, Tuple, List\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# making sure the experiments are reproducible\n",
    "seed = 2109\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bde39444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([500, 1, 128000]), torch.Size([500, 3])\n",
      "Valid: torch.Size([125, 1, 128000]), torch.Size([125, 3])\n",
      "Test: torch.Size([308, 1, 128000]), torch.Size([308, 3])\n"
     ]
    }
   ],
   "source": [
    "features_path = \"../features/propor2022/\"\n",
    "\n",
    "# loading training features\n",
    "X_train = read_feature(path=features_path, fold=\"0\", name=\"X_train.pth\")\n",
    "y_train = read_feature(path=features_path, fold=\"0\", name=\"y_train.pth\")\n",
    "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
    "\n",
    "# loading validation features\n",
    "X_valid = read_feature(path=features_path, fold=\"0\", name=\"X_valid.pth\")\n",
    "y_valid = read_feature(path=features_path, fold=\"0\", name=\"y_valid.pth\")\n",
    "print(f\"Valid: {X_valid.shape}, {y_valid.shape}\")\n",
    "\n",
    "# loading testing features\n",
    "X_test = read_feature(path=features_path, fold=None, name=\"X_test.pth\")\n",
    "y_test = read_feature(path=features_path, fold=None, name=\"y_test.pth\")\n",
    "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b07bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the parameters configuration file\n",
    "params = json.load(open(\"../config/mode_1.json\", \"r\"))\n",
    "\n",
    "# parameters defination\n",
    "k_fold = None\n",
    "max_seconds = 16\n",
    "\n",
    "if \"kfold\" in params.keys():\n",
    "    k_fold = params[\"kfold\"][\"num_k\"]\n",
    "\n",
    "max_samples = max_seconds * int(params[\"sample_rate\"])\n",
    "\n",
    "if params[\"mode\"] != \"mode_3\":\n",
    "    feature_config = params[\"feature\"]\n",
    "else:\n",
    "    feature_config = {}\n",
    "\n",
    "feature_config[\"sample_rate\"] = int(params[\"sample_rate\"])\n",
    "data_augmentation_config = params[\"data_augmentation\"]\n",
    "dataset = params[\"dataset\"]\n",
    "wavelet_config = params[\"wavelet\"]\n",
    "\n",
    "model_config = params[\"model\"]\n",
    "model_config[\"use_lr_scheduler\"] = False\n",
    "model_config[\"epochs\"] = 200\n",
    "model_config[\"batch_size\"] = 16\n",
    "\n",
    "mode = params[\"mode\"]\n",
    "\n",
    "feat_path = os.path.join(params[\"output_path\"], params[\"dataset\"])\n",
    "\n",
    "if dataset == \"propor2022\":\n",
    "    if data_augmentation_config[\"target\"] == \"majority\":\n",
    "        data_augment_target = [0]\n",
    "    elif data_augmentation_config[\"target\"] == \"minority\":\n",
    "        data_augment_target = [1, 2]\n",
    "    elif data_augmentation_config[\"target\"] == \"all\":\n",
    "        data_augment_target = [0, 1, 2]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid arguments for target. Should be 'all', 'majority' or 'minority\")\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e24ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.input_channels = 1\n",
    "        self.linear_input_features = 185856\n",
    "            \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=self.input_channels,\n",
    "                out_channels=64,\n",
    "                kernel_size=(12, 12)\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2, 2)\n",
    "            ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=(12, 12)\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(\n",
    "                kernel_size=(2, 2)\n",
    "            ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(\n",
    "                in_features=self.linear_input_features,\n",
    "                out_features=128\n",
    "            ),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.Linear(\n",
    "                in_features=128,\n",
    "                out_features=3\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.model.apply(weight_init)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        X: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a3df5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200\n",
      "\n",
      "Epoch: 1\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.690344\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.745476\n",
      "\n",
      "Epoch: 2/200\n",
      "\n",
      "Epoch: 2\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.664315\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.738709\n",
      "\n",
      "Epoch: 3/200\n",
      "\n",
      "Epoch: 3\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.655119\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.738622\n",
      "\n",
      "Epoch: 4/200\n",
      "\n",
      "Epoch: 4\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.669426\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.742769\n",
      "\n",
      "Epoch: 5/200\n",
      "\n",
      "Epoch: 5\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.660821\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.736576\n",
      "\n",
      "Epoch: 6/200\n",
      "\n",
      "Epoch: 6\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.665350\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.737303\n",
      "\n",
      "Epoch: 7/200\n",
      "\n",
      "Epoch: 7\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.668242\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735579\n",
      "\n",
      "Epoch: 8/200\n",
      "\n",
      "Epoch: 8\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.667920\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.734767\n",
      "\n",
      "Epoch: 9/200\n",
      "\n",
      "Epoch: 9\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.652888\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735189\n",
      "\n",
      "Epoch: 10/200\n",
      "\n",
      "Epoch: 10\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.658910\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.734472\n",
      "\n",
      "Epoch: 11/200\n",
      "\n",
      "Epoch: 11\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.658997\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.740780\n",
      "\n",
      "Epoch: 12/200\n",
      "\n",
      "Epoch: 12\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.653925\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735363\n",
      "\n",
      "Epoch: 13/200\n",
      "\n",
      "Epoch: 13\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.665802\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.734751\n",
      "\n",
      "Epoch: 14/200\n",
      "\n",
      "Epoch: 14\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.656026\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.732904\n",
      "\n",
      "Epoch: 15/200\n",
      "\n",
      "Epoch: 15\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.661354\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.736192\n",
      "\n",
      "Epoch: 16/200\n",
      "\n",
      "Epoch: 16\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.657754\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.731905\n",
      "\n",
      "Epoch: 17/200\n",
      "\n",
      "Epoch: 17\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.657619\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.733565\n",
      "\n",
      "Epoch: 18/200\n",
      "\n",
      "Epoch: 18\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.656282\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735821\n",
      "\n",
      "Epoch: 19/200\n",
      "\n",
      "Epoch: 19\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.658957\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.733769\n",
      "\n",
      "Epoch: 20/200\n",
      "\n",
      "Epoch: 20\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.652567\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.731943\n",
      "\n",
      "Epoch: 21/200\n",
      "\n",
      "Epoch: 21\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.664324\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.730796\n",
      "\n",
      "Epoch: 22/200\n",
      "\n",
      "Epoch: 22\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.650546\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.734943\n",
      "\n",
      "Epoch: 23/200\n",
      "\n",
      "Epoch: 23\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.667712\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.734479\n",
      "\n",
      "Epoch: 24/200\n",
      "\n",
      "Epoch: 24\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.656654\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.734824\n",
      "\n",
      "Epoch: 25/200\n",
      "\n",
      "Epoch: 25\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.654436\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.734941\n",
      "\n",
      "Epoch: 26/200\n",
      "\n",
      "Epoch: 26\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.654746\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.736548\n",
      "\n",
      "Epoch: 27/200\n",
      "\n",
      "Epoch: 27\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.645326\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.736446\n",
      "\n",
      "Epoch: 28/200\n",
      "\n",
      "Epoch: 28\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.655732\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.736463\n",
      "\n",
      "Epoch: 29/200\n",
      "\n",
      "Epoch: 29\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.657054\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.737714\n",
      "\n",
      "Epoch: 30/200\n",
      "\n",
      "Epoch: 30\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.652879\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735729\n",
      "\n",
      "Epoch: 31/200\n",
      "\n",
      "Epoch: 31\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.649598\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735357\n",
      "\n",
      "Epoch: 32/200\n",
      "\n",
      "Epoch: 32\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.648203\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735041\n",
      "\n",
      "Epoch: 33/200\n",
      "\n",
      "Epoch: 33\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.646745\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735436\n",
      "\n",
      "Epoch: 34/200\n",
      "\n",
      "Epoch: 34\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.655847\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735220\n",
      "\n",
      "Epoch: 35/200\n",
      "\n",
      "Epoch: 35\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.651481\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735369\n",
      "\n",
      "Epoch: 36/200\n",
      "\n",
      "Epoch: 36\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.646256\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.737594\n",
      "\n",
      "Epoch: 37/200\n",
      "\n",
      "Epoch: 37\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.647742\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735119\n",
      "\n",
      "Epoch: 38/200\n",
      "\n",
      "Epoch: 38\n",
      "Train F1-Score: 0.301893\n",
      "Train Loss: 0.644064\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.743060\n",
      "\n",
      "Epoch: 39/200\n",
      "\n",
      "Epoch: 39\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.665815\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.735666\n",
      "\n",
      "Epoch: 40/200\n",
      "\n",
      "Epoch: 40\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.651633\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.755696\n",
      "\n",
      "Epoch: 41/200\n",
      "\n",
      "Epoch: 41\n",
      "Train F1-Score: 0.292555\n",
      "Train Loss: 0.656522\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.736073\n",
      "\n",
      "Epoch: 42/200\n",
      "\n",
      "Epoch: 42\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.642427\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.738461\n",
      "\n",
      "Epoch: 43/200\n",
      "\n",
      "Epoch: 43\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.649613\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.738258\n",
      "\n",
      "Epoch: 44/200\n",
      "\n",
      "Epoch: 44\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.645923\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.739085\n",
      "\n",
      "Epoch: 45/200\n",
      "\n",
      "Epoch: 45\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.645152\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.740565\n",
      "\n",
      "Epoch: 46/200\n",
      "\n",
      "Epoch: 46\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.651919\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.743413\n",
      "\n",
      "Epoch: 47/200\n",
      "\n",
      "Epoch: 47\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.652582\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.739555\n",
      "\n",
      "Epoch: 48/200\n",
      "\n",
      "Epoch: 48\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.647623\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.738954\n",
      "\n",
      "Epoch: 49/200\n",
      "\n",
      "Epoch: 49\n",
      "Train F1-Score: 0.292975\n",
      "Train Loss: 0.641894\n",
      "Validation F1-Score: 0.294643\n",
      "Validation Loss: 0.746933\n",
      "\n",
      "Epoch: 50/200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 82\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m train_f1, train_loss \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m     75\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     76\u001b[0m     dataloader\u001b[38;5;241m=\u001b[39mtraining_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     loss\u001b[38;5;241m=\u001b[39mloss\n\u001b[1;32m     80\u001b[0m )\n\u001b[0;32m---> 82\u001b[0m valid_f1, valid_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain F1-Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m1.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/greca/HD/GitHub/ser-wavelet/train.py:119\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, loss, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m validation_f1 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, (batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m    120\u001b[0m         data \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    121\u001b[0m         target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/media/greca/HD/anaconda3/envs/ser/lib/python3.8/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/media/greca/HD/anaconda3/envs/ser/lib/python3.8/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/media/greca/HD/anaconda3/envs/ser/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/media/greca/HD/anaconda3/envs/ser/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# creating and defining the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available and model_config[\"use_gpu\"] else \"cpu\")\n",
    "\n",
    "model = CNN().to(device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=model_config[\"learning_rate\"],\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1e-9\n",
    ")\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "scheduler = None\n",
    "\n",
    "# creating the model checkpoint object\n",
    "sbm = SaveBestModel(\n",
    "    output_dir=os.path.join(model_config[\"output_path\"], dataset, mode, model_config[\"name\"]),\n",
    "    model_name=model_config[\"name\"]\n",
    ")\n",
    "\n",
    "if model_config[\"use_lr_scheduler\"]:\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# creating the training dataloader\n",
    "training_dataloader = create_dataloader(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    feature_config=feature_config,\n",
    "    wavelet_config=wavelet_config,\n",
    "    data_augmentation_config=data_augmentation_config,\n",
    "    num_workers=0,\n",
    "    mode=mode,\n",
    "    shuffle=False,\n",
    "    training=True,\n",
    "    batch_size=model_config[\"batch_size\"],\n",
    "    data_augment_target=data_augment_target,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "# creating the validation dataloader\n",
    "validation_dataloader = create_dataloader(\n",
    "    X=X_valid,\n",
    "    y=y_valid,\n",
    "    feature_config=feature_config,\n",
    "    wavelet_config=wavelet_config,\n",
    "    data_augmentation_config=data_augmentation_config,\n",
    "    num_workers=0,\n",
    "    mode=mode,\n",
    "    shuffle=False,\n",
    "    training=False,\n",
    "    batch_size=model_config[\"batch_size\"],\n",
    "    data_augment_target=data_augment_target,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "# training loop\n",
    "for epoch in range(1, model_config[\"epochs\"] + 1):\n",
    "    print(f\"Epoch: {epoch}/{model_config['epochs']}\")\n",
    "\n",
    "    train_f1, train_loss = train(\n",
    "        device=device,\n",
    "        dataloader=training_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        model=model,\n",
    "        loss=loss\n",
    "    )\n",
    "\n",
    "    valid_f1, valid_loss = evaluate(\n",
    "        device=device,\n",
    "        dataloader=validation_dataloader,\n",
    "        model=model,\n",
    "        loss=loss\n",
    "    )\n",
    "\n",
    "    print(f\"\\nEpoch: {epoch}\")\n",
    "    print(f\"Train F1-Score: {train_f1:1.6f}\")\n",
    "    print(f\"Train Loss: {train_loss:1.6f}\")\n",
    "    print(f\"Validation F1-Score: {valid_f1:1.6f}\")\n",
    "    print(f\"Validation Loss: {valid_loss:1.6f}\\n\")\n",
    "\n",
    "    # updating learning rate\n",
    "    if not scheduler is None:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0922b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
