{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5329f4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fab4bdfb830>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(\n",
    "                  os.path.dirname(\"test-split-audio\"), \n",
    "                  os.pardir)\n",
    ")\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from src.utils import read_feature, pad_features\n",
    "from src.features import extract_melspectrogram, extract_mfcc\n",
    "\n",
    "# making sure the experiments are reproducible\n",
    "seed = 2109\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d85a35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([500, 1, 256000]), torch.Size([500, 3])\n",
      "Valid: torch.Size([125, 1, 256000]), torch.Size([125, 3])\n",
      "Test: torch.Size([308, 1, 256000]), torch.Size([308, 3])\n"
     ]
    }
   ],
   "source": [
    "features_path = \"../features/propor2022/\"\n",
    "\n",
    "# loading training features\n",
    "X_train = read_feature(path=features_path, fold=\"0\", name=\"X_train.pth\")\n",
    "y_train = read_feature(path=features_path, fold=\"0\", name=\"y_train.pth\")\n",
    "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
    "\n",
    "# loading validation features\n",
    "X_valid = read_feature(path=features_path, fold=\"0\", name=\"X_valid.pth\")\n",
    "y_valid = read_feature(path=features_path, fold=\"0\", name=\"y_valid.pth\")\n",
    "print(f\"Valid: {X_valid.shape}, {y_valid.shape}\")\n",
    "\n",
    "# loading testing features\n",
    "X_test = read_feature(path=features_path, fold=None, name=\"X_test.pth\")\n",
    "y_test = read_feature(path=features_path, fold=None, name=\"y_test.pth\")\n",
    "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307d0cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 32, 1, 8000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = X_train.view(X_train.size(0), -1, X_train.size(1), 8000)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdb008f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 32, 5, 16, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pywt\n",
    "from copy import deepcopy\n",
    "\n",
    "total_batches = test.shape[0]\n",
    "total_frames = test.shape[1]\n",
    "feats = []\n",
    "feature = \"mfcc\"\n",
    "\n",
    "for i in range(total_batches):\n",
    "        \n",
    "    for j in range(total_frames):\n",
    "        audio = deepcopy(test[i, j, :, :].detach().squeeze().numpy())\n",
    "\n",
    "        coeffs = pywt.wavedec(\n",
    "            data=audio,\n",
    "            wavelet=\"db8\",\n",
    "            mode=\"symmetric\",\n",
    "            level=4\n",
    "        )\n",
    "\n",
    "        coeffs = [torch.from_numpy(c).unsqueeze(0) for c in coeffs]\n",
    "\n",
    "        for coeff in coeffs:\n",
    "            if feature == \"mfcc\":\n",
    "                feat = extract_mfcc(\n",
    "                    audio=coeff,\n",
    "                    sample_rate=8000,\n",
    "                    n_fft=512,\n",
    "                    hop_length=256,\n",
    "                    n_mfcc=64,\n",
    "                    f_min=0,\n",
    "                    f_max=None\n",
    "                )\n",
    "            elif feature == \"mel_spectrogram\":\n",
    "                feat = extract_melspectrogram(\n",
    "                    audio=coeff,\n",
    "                    sample_rate=8000,\n",
    "                    n_fft=512,\n",
    "                    hop_length=256,\n",
    "                    n_mels=128\n",
    "                )\n",
    "\n",
    "            feats.append(feat)\n",
    "\n",
    "# padding the mel spectrograms to be the same size\n",
    "max_height = max([x.size(1) for x in feats])\n",
    "max_width = max([x.size(2) for x in feats])\n",
    "\n",
    "feats = pad_features(\n",
    "    features=feats,\n",
    "    max_height=max_height,\n",
    "    max_width=max_width\n",
    ")\n",
    "feats = torch.concat(feats, dim=0)\n",
    "feats = feats.permute(0, 2, 1) # time and frequency axis permutation\n",
    "feats = feats.view(test.shape[0], test.shape[1], -1, feats.shape[1], feats.shape[2])\n",
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b5b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All credits to: https://discuss.pytorch.org/t/any-pytorch-function-can-work-as-keras-timedistributed/1346\n",
    "class TimeDistributed(nn.Module):\n",
    "    \"\"\"\n",
    "    Mimics the Keras TimeDistributed layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, module: torch.nn.Module, batch_first: bool, layer_name: str):\n",
    "        super(TimeDistributed, self).__init__()\n",
    "        self.module = module\n",
    "        self.batch_first = batch_first\n",
    "        self.layer_name = layer_name\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if len(x.size()) <= 2:\n",
    "            return self.module(x)\n",
    "\n",
    "        # Squash samples and timesteps into a single axis\n",
    "        x_reshape = x.contiguous().view(-1, x.size(-3), x.size(-2), x.size(-1))\n",
    "\n",
    "        y = self.module(x_reshape)\n",
    "\n",
    "        if self.layer_name == \"convolutional\" or self.layer_name == \"max_pooling\":\n",
    "\n",
    "            # We have to reshape Y\n",
    "            if self.batch_first:\n",
    "                y = y.contiguous().view(\n",
    "                    x.size(0), x.size(1), y.size(-3), y.size(-2), y.size(-1)\n",
    "                )\n",
    "            else:\n",
    "                y = y.view(-1, x.size(1), y.size(-1))\n",
    "\n",
    "        else:\n",
    "\n",
    "            # We have to reshape Y\n",
    "            if self.batch_first:\n",
    "                y = y.contiguous().view(x.size(0), x.size(1), y.size(-1))\n",
    "            else:\n",
    "                y = y.view(-1, x.size(1), y.size(-1))\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extract_LSTM_Output(nn.Module):\n",
    "    \"\"\"\n",
    "    Extracts only the output from the BiLSTM layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = x[1]\n",
    "        output = output.permute(1, 0, 2).flatten(start_dim=1)\n",
    "        return output\n",
    "    \n",
    "class CNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            TimeDistributed(\n",
    "                nn.Conv2d(in_channels=5, out_channels=64, kernel_size=2),\n",
    "                batch_first=True,\n",
    "                layer_name=\"convolutional\"\n",
    "            ),\n",
    "            TimeDistributed(\n",
    "                nn.BatchNorm2d(64),\n",
    "                batch_first=True,\n",
    "                layer_name=\"convolutional\"\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            TimeDistributed(\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                batch_first=True,\n",
    "                layer_name=\"convolutional\"\n",
    "            ),\n",
    "            TimeDistributed(\n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=2),\n",
    "                batch_first=True,\n",
    "                layer_name=\"convolutional\"\n",
    "            ),\n",
    "            TimeDistributed(\n",
    "                nn.BatchNorm2d(128),\n",
    "                batch_first=True,\n",
    "                layer_name=\"convolutional\"\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            TimeDistributed(\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                batch_first=True,\n",
    "                layer_name=\"convolutional\"\n",
    "            ),\n",
    "            TimeDistributed(\n",
    "                nn.Flatten(),\n",
    "                batch_first=True,\n",
    "                layer_name=\"flatten\"\n",
    "            ),\n",
    "            TimeDistributed(\n",
    "                nn.Linear(in_features=5760, out_features=128),\n",
    "                batch_first=True,\n",
    "                layer_name=\"dense\",\n",
    "            ),\n",
    "            nn.LSTM(\n",
    "                input_size=128,\n",
    "                hidden_size=128,\n",
    "                num_layers=1,\n",
    "                batch_first=True,\n",
    "                bidirectional=True,\n",
    "            ),\n",
    "            Extract_LSTM_Output(),\n",
    "            nn.Linear(\n",
    "                in_features=256,\n",
    "                out_features=3\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(X)\n",
    "\n",
    "model = CNN()\n",
    "output = model(feats)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a224439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
