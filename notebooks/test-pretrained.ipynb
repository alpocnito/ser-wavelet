{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0e4d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0f500d6c10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(\n",
    "                  os.path.dirname(\"test-pretrained\"), \n",
    "                  os.pardir)\n",
    ")\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "from src.features import extract_wavelet_from_raw_audio\n",
    "from src.utils import feature_extraction_pipeline, read_features_files, choose_model, read_feature, pad_features\n",
    "from src.models.utils import SaveBestModel, weight_init\n",
    "from src.models.cnn3 import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from typing import Dict, Tuple, List, Union, Iterable\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# making sure the experiments are reproducible\n",
    "seed = 2109\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def seed_worker(worker_id: int):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e093127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer: torch.optim.Adam,\n",
    "    loss: torch.nn.CrossEntropyLoss,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Function responsible for the model training.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): the created model.\n",
    "        dataloader (DataLoader): the training dataloader.\n",
    "        optimizer (torch.optim.Adam): the optimizer used.\n",
    "        loss (torch.nn.CrossEntropyLoss): the loss function used.\n",
    "        device (torch.device): which device to use.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: the training f1 and loss, respectively.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for index, (batch) in enumerate(dataloader, start=1):\n",
    "        data = batch[\"features\"].to(device)\n",
    "        target = batch[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        data = data.to(dtype=torch.float32)\n",
    "        target = target.to(dtype=torch.float32)\n",
    "        \n",
    "        output = model(data)\n",
    "\n",
    "        l = loss(output['clipwise_output'], target)\n",
    "        train_loss += l.item()\n",
    "        \n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction = output['clipwise_output'].argmax(dim=-1, keepdim=True).to(dtype=torch.int)\n",
    "        prediction = prediction.detach().cpu().numpy()\n",
    "        predictions.extend(prediction.tolist())\n",
    "        \n",
    "        target = target.argmax(dim=-1, keepdim=True).to(dtype=torch.int)\n",
    "        target = target.detach().cpu().numpy()\n",
    "        targets.extend(target.tolist())\n",
    "        \n",
    "    train_loss = train_loss/index\n",
    "    train_f1 = classification_report(\n",
    "        targets,\n",
    "        predictions,\n",
    "        digits=6,\n",
    "        output_dict=True,\n",
    "        zero_division=0.0\n",
    "    )\n",
    "    train_f1 = train_f1[\"macro avg\"][\"f1-score\"]\n",
    "    return train_f1, train_loss\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    loss: torch.nn.CrossEntropyLoss,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Function responsible for the model evaluation.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): the created model.\n",
    "        dataloader (DataLoader): the validaiton dataloader.\n",
    "        loss (torch.nn.CrossEntropyLoss): the loss function used.\n",
    "        device (torch.device): which device to use.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: the validation f1 and loss, respectively.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    validation_loss = 0.0\n",
    "    validation_f1 = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for index, (batch) in enumerate(dataloader):\n",
    "            data = batch[\"features\"].to(device)\n",
    "            target = batch[\"labels\"].to(device)\n",
    "\n",
    "            data = data.to(dtype=torch.float32)\n",
    "            target = target.to(dtype=torch.float32)\n",
    "                        \n",
    "            output = model(data)\n",
    "            \n",
    "            l = loss(output['clipwise_output'], target)\n",
    "            validation_loss += l.item()\n",
    "            \n",
    "            prediction = output['clipwise_output'].argmax(dim=-1, keepdim=True).to(dtype=torch.int)\n",
    "            prediction = prediction.detach().cpu().numpy()\n",
    "            predictions.extend(prediction.tolist())\n",
    "            \n",
    "            target = target.argmax(dim=-1, keepdim=True).to(dtype=torch.int)\n",
    "            target = target.detach().cpu().numpy()\n",
    "            targets.extend(target.tolist())\n",
    "    \n",
    "    validation_loss = validation_loss/index\n",
    "    validation_f1 = classification_report(\n",
    "        targets,\n",
    "        predictions,\n",
    "        digits=6,\n",
    "        output_dict=True,\n",
    "        zero_division=0.0\n",
    "    )\n",
    "    validation_f1 = validation_f1[\"macro avg\"][\"f1-score\"]\n",
    "    return validation_f1, validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3ba736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        feature_config: Dict,\n",
    "        wavelet_config: Dict,\n",
    "        data_augmentation_config: Union[Dict, None],\n",
    "        training: bool,\n",
    "        data_augment_target: Union[str, None]\n",
    "    ) -> None:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.feature_config = feature_config\n",
    "        self.wavelet_config = wavelet_config\n",
    "        self.data_augmentation_config = data_augmentation_config\n",
    "        self.training = training\n",
    "        self.data_augment_target = data_augment_target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "        \n",
    "    def __getitem__(\n",
    "        self,\n",
    "        index: int\n",
    "    ) -> Dict:\n",
    "        batch = {}\n",
    "        audio = deepcopy(self.X[index, :, :])\n",
    "        \n",
    "        if self.data_augment_target is not None:\n",
    "            if self.y[index].argmax(dim=-1, keepdim=False).item() in self.data_augment_target and self.training and \\\n",
    "                self.data_augmentation_config[\"mode\"] == \"raw_audio\":\n",
    "                audio = _apply_augmentation_raw_audio(\n",
    "                    audio=audio,\n",
    "                    data_augmentation_config=self.data_augmentation_config,\n",
    "                    feature_config=self.feature_config\n",
    "                )\n",
    "        \n",
    "        assert audio.ndim == 2 and audio.shape[0] == 1\n",
    "                \n",
    "        if self.feature_config[\"name\"] == \"mel_spectrogram\":\n",
    "            feat = extract_melspectrogram(\n",
    "                audio=audio,\n",
    "                sample_rate=self.feature_config[\"sample_rate\"],\n",
    "                n_fft=self.feature_config[\"n_fft\"],\n",
    "                hop_length=self.feature_config[\"hop_length\"],\n",
    "                n_mels=self.feature_config[\"n_mels\"]\n",
    "            )\n",
    "        elif self.feature_config[\"name\"] == \"mfcc\":\n",
    "            feat = extract_mfcc(\n",
    "                audio=audio,\n",
    "                sample_rate=self.feature_config[\"sample_rate\"],\n",
    "                n_fft=self.feature_config[\"n_fft\"],\n",
    "                hop_length=self.feature_config[\"hop_length\"],\n",
    "                n_mfcc=self.feature_config[\"n_mfcc\"]\n",
    "            )\n",
    "        \n",
    "        assert feat.ndim == 3 and feat.shape[0] == 1\n",
    "\n",
    "        if self.data_augment_target is not None:\n",
    "            if self.y[index].argmax(dim=-1, keepdim=False).item() in self.data_augment_target and self.training and \\\n",
    "                self.data_augmentation_config[\"mode\"] == \"feature\":\n",
    "                feat = _apply_augmentation_feature(\n",
    "                    audio=feat,\n",
    "                    data_augmentation_config=self.data_augmentation_config,\n",
    "                    feature_config=self.feature_config\n",
    "                )\n",
    "        \n",
    "        assert feat.ndim == 3 and feat.shape[0] == 1\n",
    "        \n",
    "        feat = feat.permute(0, 2, 1) # time and frequency axis permutation\n",
    "        \n",
    "        X, _ = extract_wavelet_from_spectrogram(\n",
    "            spectrogram=feat.squeeze(0),\n",
    "            wavelet=self.wavelet_config[\"name\"],\n",
    "            maxlevel=self.wavelet_config[\"level\"],\n",
    "            type=self.wavelet_config[\"type\"],\n",
    "            mode=self.wavelet_config[\"mode\"]\n",
    "        )\n",
    "\n",
    "        assert X.ndim == 2\n",
    "\n",
    "        batch[\"features\"] = X.unsqueeze(0)\n",
    "        batch[\"labels\"] = self.y[index]\n",
    "        return batch\n",
    "    \n",
    "def create_dataloader(\n",
    "    X: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    batch_size: int,\n",
    "    wavelet_config: Dict,\n",
    "    worker_init_fn: Iterable,\n",
    "    generator: torch.Generator,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = True,\n",
    "    training: bool = True\n",
    ") -> DataLoader:\n",
    "    \n",
    "    # creating the custom dataset\n",
    "    dataset = Custom_Dataset(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        wavelet_config=wavelet_config,\n",
    "        training=training\n",
    "    )\n",
    "    \n",
    "    # creating the dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=False,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "        generator=generator\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe38014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transfer_Cnn6(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax, classes_num, freeze_base):\n",
    "        \"\"\"Classifier for a new task using pretrained Cnn14 as a sub module.\n",
    "        \"\"\"\n",
    "        super(Transfer_Cnn6, self).__init__()\n",
    "        audioset_classes_num = 527\n",
    "        \n",
    "        self.base = Cnn6(sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "            fmax, audioset_classes_num)\n",
    "\n",
    "        # Transfer to another task layer\n",
    "        self.fc_transfer = nn.Linear(512, classes_num, bias=True)\n",
    "\n",
    "        if freeze_base:\n",
    "            # Freeze AudioSet pretrained layers\n",
    "            for param in self.base.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.fc_transfer)\n",
    "\n",
    "    def load_from_pretrain(self, pretrained_checkpoint_path):\n",
    "        checkpoint = torch.load(pretrained_checkpoint_path)\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        output_dict = self.base(input, mixup_lambda)\n",
    "        embedding = output_dict['embedding']\n",
    "        clipwise_output = torch.log_softmax(self.fc_transfer(embedding), dim=-1)\n",
    "        output_dict['clipwise_output'] = clipwise_output\n",
    " \n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a12db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([500, 1, 128000]), torch.Size([500, 3])\n",
      "Valid: torch.Size([125, 1, 128000]), torch.Size([125, 3])\n",
      "Test: torch.Size([308, 1, 128000]), torch.Size([308, 3])\n"
     ]
    }
   ],
   "source": [
    "features_path = \"../features/propor2022/\"\n",
    "\n",
    "# loading training features\n",
    "X_train = read_feature(path=features_path, fold=\"0\", name=\"X_train.pth\")\n",
    "y_train = read_feature(path=features_path, fold=\"0\", name=\"y_train.pth\")\n",
    "print(f\"Train: {X_train.shape}, {y_train.shape}\")\n",
    "\n",
    "# loading validation features\n",
    "X_valid = read_feature(path=features_path, fold=\"0\", name=\"X_valid.pth\")\n",
    "y_valid = read_feature(path=features_path, fold=\"0\", name=\"y_valid.pth\")\n",
    "print(f\"Valid: {X_valid.shape}, {y_valid.shape}\")\n",
    "\n",
    "# loading testing features\n",
    "X_test = read_feature(path=features_path, fold=None, name=\"X_test.pth\")\n",
    "y_test = read_feature(path=features_path, fold=None, name=\"y_test.pth\")\n",
    "print(f\"Test: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c134a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Cnn6' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available \u001b[38;5;129;01mand\u001b[39;00m model_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m feat_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_path\u001b[39m\u001b[38;5;124m\"\u001b[39m], params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCnn6\u001b[49m(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Load pretrained model\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrain:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Cnn6' is not defined"
     ]
    }
   ],
   "source": [
    "# reading the parameters configuration file\n",
    "params = json.load(open(\"../config/mode_2.json\", \"r\"))\n",
    "\n",
    "if params[\"mode\"] != \"mode_3\":\n",
    "    feature_config = params[\"feature\"]\n",
    "else:\n",
    "    feature_config = {}\n",
    "\n",
    "sample_rate = 32000\n",
    "window_size = 1024\n",
    "hop_size = 320\n",
    "mel_bins = 64\n",
    "fmin = 0\n",
    "fmax = 32000\n",
    "freeze_base = False\n",
    "pretrained_checkpoint_path = \"/home/greca/Downloads/Cnn6_mAP=0.343.pth\"\n",
    "pretrain = False\n",
    "classes_num = 3\n",
    "\n",
    "data_augmentation_config = None\n",
    "dataset = params[\"dataset\"]\n",
    "wavelet_config = params[\"wavelet\"]\n",
    "model_config = params[\"model\"]\n",
    "mode = params[\"mode\"]\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available and model_config[\"use_gpu\"] else \"cpu\")\n",
    "feat_path = os.path.join(params[\"output_path\"], params[\"dataset\"])\n",
    "\n",
    "model = CNN3_Mode1(sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num)\n",
    "\n",
    "# Load pretrained model\n",
    "if pretrain:\n",
    "    print('Load pretrained model from {}'.format(pretrained_checkpoint_path))\n",
    "    model.load_from_pretrain(pretrained_checkpoint_path)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print('Load pretrained model successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and defining the model\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=model_config[\"learning_rate\"],\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1e-9\n",
    ")\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# creating the training dataloader\n",
    "training_dataloader = create_dataloader(\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    wavelet_config=wavelet_config,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    training=True,\n",
    "    batch_size=model_config[\"batch_size\"],\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "# creating the validation dataloader\n",
    "validation_dataloader = create_dataloader(\n",
    "    X=X_valid,\n",
    "    y=y_valid,\n",
    "    wavelet_config=wavelet_config,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    training=False,\n",
    "    batch_size=model_config[\"batch_size\"],\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "train_f1, train_loss = train(\n",
    "    device=device,\n",
    "    dataloader=training_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    model=model,\n",
    "    loss=loss\n",
    ")\n",
    "\n",
    "valid_f1, valid_loss = evaluate(\n",
    "    device=device,\n",
    "    dataloader=validation_dataloader,\n",
    "    model=model,\n",
    "    loss=loss\n",
    ")\n",
    "\n",
    "# training loop\n",
    "for epoch in range(1, model_config[\"epochs\"] + 1):\n",
    "    print(f\"Epoch: {epoch}/{model_config['epochs']}\")\n",
    "\n",
    "    train_f1, train_loss = train(\n",
    "        device=device,\n",
    "        dataloader=training_dataloader,\n",
    "        optimizer=optimizer,\n",
    "        model=model,\n",
    "        loss=loss\n",
    "    )\n",
    "\n",
    "    valid_f1, valid_loss = evaluate(\n",
    "        device=device,\n",
    "        dataloader=validation_dataloader,\n",
    "        model=model,\n",
    "        loss=loss\n",
    "    )\n",
    "\n",
    "    print(f\"\\nEpoch: {epoch}\")\n",
    "    print(f\"Train F1-Score: {train_f1:1.6f}\")\n",
    "    print(f\"Train Loss: {train_loss:1.6f}\")\n",
    "    print(f\"Validation F1-Score: {valid_f1:1.6f}\")\n",
    "    print(f\"Validation Loss: {valid_loss:1.6f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
